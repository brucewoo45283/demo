{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdde4013",
   "metadata": {},
   "source": [
    "# 人工神經網路 (Artificial Neural Network)\n",
    "### 當訊號量超過了某個閾值 (Threshold) 時，細胞體就會產生電流、通過突觸傳到其他神經元，建立一個\"萬用函數\"\n",
    "# 感知機(Perceptron)模型 :\n",
    "### 單層感知機：邏輯門、無法處理XOR 問題 [ n個輸入值x 乘以 神經元(權重) = 輸出值y]\n",
    "### 多層感知機：Rumelhart、Hinton 等人提出「反向傳播演算法」(Backpropagation) 訓練神經網路， 催生出具備非線性學習能力的多層感知機(Multi-Layer Perceptron)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168058d",
   "metadata": {},
   "source": [
    "# 參考資料\n",
    "### http://debussy.im.nuu.edu.tw/sjchen/MachineLearning/final/NN_BPN.pdf\n",
    "### http://chur.chu.edu.tw/bitstream/987654321/1823/7/NC089CHPI039201507.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcaa573",
   "metadata": {},
   "source": [
    "# 邏輯門 https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E9%96%98\n",
    "###        \n",
    "### AND：  a為1且b為1，才會輸出1\n",
    "### OR：   a、b任一為1即可\n",
    "### XOR：  a或b任一為1才會是1，同時為1輸出是0\n",
    "### NOT：  0變1、1變0\n",
    "# 必須使用兩層，才能解決XOR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb9dd0",
   "metadata": {},
   "source": [
    "# 建構神經網路：輸入層(N個模型混和) X 隱藏層 = 輸出層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a018c",
   "metadata": {},
   "source": [
    "# 輸入值 X 神經元 = 輸出值\n",
    "### 輸入值:來自同一個觀察的獨立變數，必須要標準化\n",
    "### 神經元:啟動函數或稱激活函數ACTIVATION FUNCTION，種類有Threshold Function, Sigmoid Function, Tangent Function, ReLU Function\n",
    "### 輸出值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7313ac",
   "metadata": {},
   "source": [
    "# 激活函數(Activation Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a1cec",
   "metadata": {},
   "source": [
    "## (一)Threshold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634a2ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def threshold_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(int)\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([-1,1,2])\n",
    "threshold_function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71704d6",
   "metadata": {},
   "source": [
    "## (二)Sigmoid Function：\n",
    "### 1. 求導數容易\n",
    "### 2. 無法表示負數的結果\n",
    "### 3. 梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1859a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.73105858, 0.88079708])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_function(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "x = np.array([-1,1,2])\n",
    "sigmoid_function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621266a6",
   "metadata": {},
   "source": [
    "## (三) Tangent Function ：\n",
    "### 1. 收斂速度比sigmoid塊\n",
    "### 2. 可產生負\n",
    "### 3. 梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e60c71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76159416,  0.76159416,  0.96402758])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tangent_function(x):\n",
    "    return (1 - np.exp(-2*x)) / (1 +np.exp(-2*x))\n",
    "\n",
    "x = np.array([-1,1,2])\n",
    "tangent_function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035a85e",
   "metadata": {},
   "source": [
    "## (四)ReLU Function：\n",
    "### 1. 模擬動物，有閥值，超過閥值等比例輸出\n",
    "### 2. 解決梯度消失\n",
    "### 3. 神經元死亡問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb866ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu_function(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "x = np.array([-1,1,2])\n",
    "relu_function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b2ada",
   "metadata": {},
   "source": [
    "# 單層神經網路前向傳播過程（Forward Propagation）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86804a85",
   "metadata": {},
   "source": [
    "### 寫成演算法，讓電腦去運算矩陣，提升效率\n",
    "### 矩陣乘法 24:44分處 https://www.youtube.com/watch?v=T5iC9zs0ykc\n",
    "### np.array https://allaboutdataanalysis.medium.com/python%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E4%B8%89-numpy-3a938f435286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76fe4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2])\n",
    "W = np.array([[1,3,5],\\\n",
    "              [2,4,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d9f0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11, 17])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩陣乘積\n",
    "Y = np.dot(X,W)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6785ff",
   "metadata": {},
   "source": [
    "# 多層神經網路前向傳播過程（Forward Propagation）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d04f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123, 156])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2])\n",
    "W = np.array([[1,3,5],\\\n",
    "              [2,4,6]])\n",
    "W2= np.array([[1,2],\\\n",
    "              [3,4],\n",
    "              [5,6],])\n",
    "Y  = np.dot(X,W)\n",
    "Y2 = np.dot(Y,W2)\n",
    "Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf96f3",
   "metadata": {},
   "source": [
    "# 增加偏倚（bias）\n",
    "## 可以充當閥值調整激活難度，類似截距的概念，e.g. 調整分類結果的參數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3b3dc",
   "metadata": {},
   "source": [
    "### 1. 初始神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e281191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = {}\n",
    "network['w1'] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
    "network['b1'] = np.array([0.1,0.2,0.3])\n",
    "network['w2'] = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
    "network['b2'] = np.array([0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa58cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), (3,), (3, 2), (2,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network['w1'].shape,network['b1'].shape,network['w2'].shape,network['b2'].shape #權重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c9d21",
   "metadata": {},
   "source": [
    "### 2.計算傳遞過程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94bc5c",
   "metadata": {},
   "source": [
    "### 第一層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b218afef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0.5])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09083636",
   "metadata": {},
   "source": [
    "### 乘以權重，加上偏倚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e38aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3, 0.7, 1.1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.dot(x, network['w1']) + network['b1']\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122903ff",
   "metadata": {},
   "source": [
    "### 套用激活函數，做非線性轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9507a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57444252, 0.66818777, 0.75026011])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = sigmoid_function(a)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3cd8a0",
   "metadata": {},
   "source": [
    "### 乘上第二層權重，加上偏倚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77267ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51615984, 1.21402696])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 輸出值y\n",
    "y = np.dot(z, network['w2']) + network['b2']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefba26",
   "metadata": {},
   "source": [
    "# 輸出層函數Softmax：Identity Function(一比一輸出) &  Softmax Function(把結果用機率做表示)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5adb6",
   "metadata": {},
   "source": [
    "### identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de90177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51615984, 1.21402696])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = y\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d21032",
   "metadata": {},
   "source": [
    "### softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e88040fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29832608, 0.70167392])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y / y.sum() #變成機率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66fff3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  0.5,  1. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([-1,1,2]) #如果有負值，就此路不通\n",
    "a / a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97a6b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065306597126334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.5)  #必須用指數化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd1b803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33228528, 0.66771472])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_function(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "softmax_function(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3caf934",
   "metadata": {},
   "source": [
    "# 神經網路學習過程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0530550",
   "metadata": {},
   "source": [
    "### 「代價函數」(Cost Function) 或「損失函數」 ，(Loss Function)：一開始權重會隨機亂設，而代價函數是預測結果和真實結果之間的差距，再去調整權重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b4de5",
   "metadata": {},
   "source": [
    "## 回歸：均方誤差 Mean Squared Error來判斷差距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "890fd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_err(y_hat, y):\n",
    "    return 0.5 * np.sum((y_hat - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "781785ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-f6e7c0610b57>:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13475069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.420680743952367"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0 + 1e-8) #加入delta，避免為0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d88ee",
   "metadata": {},
   "source": [
    "## 分類問題：看交叉熵 Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a9f0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_err(y_hat, y):\n",
    "    delta = 1e-8\n",
    "    return -np.sum(y*np.log(y_hat + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ab55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
